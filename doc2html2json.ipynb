{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False\n",
    "Lego = False#not(test)\n",
    "WD = not(test) and not(Lego)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./python-pptx/doc_and_ppt/\"\n",
    "if test:\n",
    "    doc = \"test.docx\"\n",
    "    html = \"test.html\"\n",
    "    result = \"test.json\"\n",
    "elif Lego:\n",
    "    doc = \"The Lego Group.docx\"\n",
    "    html = \"The Lego Group.html\"\n",
    "    result = \"The Lego Group.json\"\n",
    "elif WD:\n",
    "    doc = \"Walt Disney Company.docx\"\n",
    "    html = \"WD.html\"\n",
    "    result = \"Walt Disney.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mammoth\n",
    "\n",
    "style_map = \"\"\"\n",
    "p[style-name='Title'] => h4:fresh\n",
    "p[style-name='Heading 1'] => h1:fresh\n",
    "p[style-name='Heading 2'] => h2:fresh\n",
    "p[style-name='Heading 3'] => h3:fresh\n",
    "p[style-name^='Heading'] => h3:fresh\n",
    "p[style-name='List'] => ui:fresh\n",
    "p[style-name='i'] => strong\n",
    "p[style-name='b'] => em\n",
    "\"\"\"\n",
    "#h4 gros titre\n",
    "#u (souligné) ignoré pour le moment\n",
    "\n",
    "\n",
    "b = open(html, 'wb')\n",
    "with open(path+doc, \"rb\") as docx_file:\n",
    "    document = mammoth.convert_to_html(docx_file, style_map=style_map)\n",
    "b.write(document.value.encode('utf8'))\n",
    "#print(document.value)\n",
    "docx_file.close()\n",
    "b.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(document.value+\"\\n\", \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup)\n",
    "#for i in soup.contents[9]:\n",
    "    #print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1 - de 1\n",
      "[-1, 1]\n",
      "h2 - 2\n",
      "[-1, 1, 2]\n",
      "h1 + de 1\n",
      "=\n",
      "[-1, 1]\n",
      "h2 - 2\n",
      "[-1, 1, 2]\n",
      "h2 = 2\n",
      "[-1, 1, 2]\n",
      "h1 + de 1\n",
      "=\n",
      "[-1, 1]\n",
      "h2 - 2\n",
      "[-1, 1, 2]\n",
      "h2 = 2\n",
      "[-1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "level = -1\n",
    "level_text = [-1]\n",
    "content = ''\n",
    "end = ['']\n",
    "while(soup.contents[i] != \"\\n\"): #lecture du fichier html\n",
    "    if(soup.contents[i].name == \"h4\"): #si title\n",
    "        level = 0\n",
    "        content += '{'+'\"type\":\"level_0\",\"content\":[{\"type\":\"title_0\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}'\n",
    "        if (soup.contents[i].next.next.name != \"p\"):\n",
    "            content += ','\n",
    "\n",
    "    if(soup.contents[i].name == \"h1\"): #si h1\n",
    "        level = 1\n",
    "        if(level_text[-1]==1):\n",
    "            print('h1 = 1')\n",
    "            content += end[-1]\n",
    "            content += '{'+'\"type\":\"level_1\",\"content\":[{\"type\":\"title_1\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}'\n",
    "        if(level_text[-1]<1):\n",
    "            print('h1 - de 1')\n",
    "            level_text += [1]\n",
    "            content += '{'+'\"type\":\"level_1\",\"content\":[{\"type\":\"title_1\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}'\n",
    "            temp = ']},'+\"\\n\"\n",
    "            end += [temp]\n",
    "        if(level_text[-1]>1):\n",
    "            while(level_text[-1] > 1):\n",
    "                print('h1 + de 1')\n",
    "                content += end[-1][:-2]\n",
    "                end = end[:-1]\n",
    "                level_text = level_text[:-1]\n",
    "            if(level_text[-1] != 1):\n",
    "                print('!=')\n",
    "                level_text += [1]\n",
    "                content += '{'+'\"type\":\"level_1\",\"content\":[{\"type\":\"title_1\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}'\n",
    "                temp = ']},'+\"\\n\"\n",
    "                end += [temp]\n",
    "            else:\n",
    "                print('=')\n",
    "                content += end[-1]\n",
    "                content += '{'+'\"type\":\"level_1\",\"content\":[{\"type\":\"title_1\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}'\n",
    "        print(level_text)\n",
    "        \n",
    "    if(soup.contents[i].name == \"h2\"): #si h2\n",
    "        level = 2\n",
    "        if(level_text[-1]==2):\n",
    "            print('h2 = 2')\n",
    "            content += end[-1]\n",
    "            content += '{'+'\"type\":\"level_2\",\"content\":[{\"type\":\"title_2\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}'\n",
    "        if(level_text[-1]<2):\n",
    "            print('h2 - 2')\n",
    "            level_text += [2]\n",
    "            content += ',{'+'\"type\":\"level_2\",\"content\":[{\"type\":\"title_2\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}'\n",
    "            temp = ']},'+\"\\n\"\n",
    "            end += [temp]\n",
    "        if(level_text[-1]>2):\n",
    "            while(level_text[-1] > 2):\n",
    "                print('h2 + 2')\n",
    "                content += end[-1][:-2]\n",
    "                end = end[:-1]\n",
    "                level_text = level_text[:-1]\n",
    "            if(level_text[-1] != 2):\n",
    "                level_text += [2]\n",
    "                content += '{'+'\"type\":\"level_2\",\"content\":[{\"type\":\"title_2\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}'\n",
    "                temp = ']},'+\"\\n\"\n",
    "                end += [temp]\n",
    "            else:\n",
    "                content += end[-1]\n",
    "                content += '{'+'\"type\":\"level_2\",\"content\":[{\"type\":\"title_2\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}'\n",
    "        print(level_text)\n",
    "      \n",
    "    if(soup.contents[i].name == \"h3\"): #si h3\n",
    "        level = 3\n",
    "        if(level_text[-1]==3):\n",
    "            print('h3 = 3')\n",
    "            content += end[-1]\n",
    "            content += '{'+'\"type\":\"level_3\",\"content\":[{\"type\":\"title_3\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}'\n",
    "        if(level_text[-1]<3):\n",
    "            print('h3 - 3')\n",
    "            level_text += [3]\n",
    "            content += ',{'+'\"type\":\"level_3\",\"content\":[{\"type\":\"title_3\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}'\n",
    "            temp = ']},'+\"\\n\"\n",
    "            end += [temp]\n",
    "        if(level_text[-1]>3):\n",
    "            while(level_text[-1] > 3):\n",
    "                print('h3 + 3')\n",
    "                content += end[-1][:-2]\n",
    "                end = end[:-1]\n",
    "                level_text = level_text[:-1]\n",
    "            if(level_text[-1] != 3):\n",
    "                level_text += [3]\n",
    "                content += '{'+'\"type\":\"level_3\",\"content\":[{\"type\":\"title_3\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}'\n",
    "                temp = ']},'+\"\\n\"\n",
    "                end += [temp]\n",
    "            else:\n",
    "                content += end[-1]\n",
    "                content += '{'+'\"type\":\"level_3\",\"content\":[{\"type\":\"title_3\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}'\n",
    "        print(level_text)\n",
    "      \n",
    "    if(soup.contents[i].name == \"ul\"): #si liste\n",
    "        content += ',{\"type\":\"plain_text\",\"content\":['\n",
    "        for l in soup.contents[i]:\n",
    "            content += '\"'+ l.text.replace('\"', \"'\") + '\",'\n",
    "        content = content[:-1]\n",
    "        content += ']}]}'+\"\\n\"\n",
    "       \n",
    "    if(soup.contents[i].name != \"h4\" and soup.contents[i].name != \"h1\" and soup.contents[i].name != \"h2\" and soup.contents[i].name != \"h3\" and soup.contents[i].name != \"ul\"): #si autre\n",
    "        if(level == 0):\n",
    "            content += ',{\"type\":\"plain_text\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}]},'+\"\\n\"\n",
    "        else:\n",
    "            content += ',{\"type\":\"plain_text\",\"content\":[\"'+soup.contents[i].text.replace('\"', \"'\")+'\"]}'+\"\\n\"\n",
    "               \n",
    "    i += 1 #incrémentation de balise\n",
    "while (len(end) != 1):\n",
    "    content += end[-1][:-2]\n",
    "    end = end[:-1]\n",
    "#print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with one plain text for the title version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = open(result, 'w')\n",
    "#if(result == \"test.json\"):\n",
    "#    d.write('{\"document_name\":\"'+result+'\",\"document_content\":['+\"\\n\"+content)\n",
    "#elif(result == \"The Lego Group.json\"):\n",
    "#    d.write('{\"document_name\":\"'+result+'\",\"document_content\":['+\"\\n\"+content+']}]}')\n",
    "#elif(result == \"Walt Disney.json\"):\n",
    "#    d.write('{\"document_name\":\"'+result+'\",\"document_content\":['+\"\\n\"+content)\n",
    "d.write('{\"document_name\":\"'+result+'\",\"document_content\":['+\"\\n\"+content+']}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}]}')\n",
    "d.close()\n",
    "e = open(result, 'r')\n",
    "#print(e.read())\n",
    "e.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.startfile(json)\n",
    "#print(result)\n",
    "import json\n",
    "while True:\n",
    "    try:\n",
    "        with open(result) as fjson:\n",
    "            data = json.load(fjson)\n",
    "        break\n",
    "    except ValueError:\n",
    "        text_file = open(result, \"r\")\n",
    "        text_string = text_file.read()\n",
    "        text_file.close()\n",
    "        text_string = text_string[:-1]\n",
    "        text_file = open(result, \"w\")\n",
    "        text_file.write(text_string)\n",
    "        text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
