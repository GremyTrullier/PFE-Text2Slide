{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Pipeline\n",
    "by Jeremy Trullier  \n",
    "- Read the JSON  \n",
    "- NLP the paragraphs  \n",
    "- Replace the paragraphs in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_json import *\n",
    "#from slide_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../data/'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# not really useful\n",
    "files = os.listdir(datapath)\n",
    "for filename in files:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"The Lego Group.json\"\n",
    "jsonpath = datapath+filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jsonpath) as fjson:\n",
    "    data = json.load(fjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_slides = data['document_content']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# printing, remove for script\n",
    "#json_slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_elements = []\n",
    "breakdown_json(json_slides, slide_elements)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# printing, remove for script\n",
    "slide_elements"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# printing, remove for script\n",
    "for item in retrieve_content(slide_elements):\n",
    "    print(len(item), item,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_extraction import _run_article_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_sentences = {}\n",
    "for item in retrieve_content(slide_elements):\n",
    "    nlp_sentences[item[0]] = _run_article_summary(item[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# printing, remove for script\n",
    "nlp_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpjsonpath = datapath+\"nlp_\"+filename"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# printing, remove for script\n",
    "#nlpjsonpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for in_sentence, out_sentence in nlp_sentences.items():\n",
    "    with fileinput.FileInput(nlpjsonpath, inplace = True, backup ='.bak', mode=\"r\") as nlpfile:\n",
    "        for line in nlpfile:\n",
    "            if in_sentence in line:\n",
    "                print(line.replace(in_sentence, out_sentence), end ='')\n",
    "            else:\n",
    "                print(line, end ='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old functions not used"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from nlp_writing import replace_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def retrieve_content_and_titles(list_slides, l):\n",
    "    \"\"\"\n",
    "    Retrieves titles and plain texts from json file\n",
    "    Parameters:\n",
    "        - list_slides : list of data in json format\n",
    "        - l : the list to be returned\n",
    "    \"\"\"\n",
    "    if (type(list_slides) == type(list())):\n",
    "        for value in list_slides:\n",
    "            if type(value) == type(str()):\n",
    "                l.append(value)\n",
    "            else:\n",
    "                retrieve_content_and_titles(value, l)\n",
    "    elif (type(list_slides) == type(dict())):\n",
    "        for key,value in list_slides.items():\n",
    "            retrieve_content_and_titles(value, l)\n",
    "    else:\n",
    "        pass\n",
    "        #print(type(list_slides))\n",
    "\n",
    "testl= []\n",
    "retrieve_content_and_titles(json_slides, testl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in testl:\n",
    "    print(i,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction based summurazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"Peter and Elizabeth took a taxi to attend the night party in the city. While in the party, Elizabeth collapsed and was rushed to the hospital. Since she was diagnosed with a brain injury, the doctor told Peter to stay besides her until she gets well. Therefore, Peter stayed with her at the hospital for 3 days without leaving.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_results = _run_article_summary(article)\n",
    "print(summary_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bix's NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import collections\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.summarization import summarize\n",
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â–¶\",summarize(article, word_count=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
