{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NLP  \n",
    "by Jeremy Trullier  \n",
    "#### Trying some NLP libraries and model\n",
    "#### Writing functions to easily retrieve relevant data from our word doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from enum import Enum\n",
    "from pptx.util import Inches\n",
    "from pptx import Presentation\n",
    "from pptx.enum.shapes import MSO_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_json import *\n",
    "from slide_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connard_de_virus.png\n",
      "default_picture.jpg\n",
      "Disney_json_ppt2.json\n",
      "example.json\n",
      "lego.json\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(datapath)\n",
    "for filename in files:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonpath = datapath+\"example.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jsonpath) as fjson:\n",
    "    data = json.load(fjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'level_0', 'content': [{'type': 'title_0', 'content': ['Document title']}, {'type': 'plain_text', 'content': ['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus. Fusce vitae lobortis quam. Proin laoreet efficitur ligula, laoreet congue neque condimentum a']}]} \n",
      "\n",
      "{'type': 'level_1', 'content': [{'type': 'title_1', 'content': ['Part 1']}, {'type': 'plain_text', 'content': ['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed.']}, {'type': 'level_2', 'content': [{'type': 'title_2', 'content': ['Part 1-1']}, {'type': 'plain_text', 'content': ['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus.', 'Nulla odio nibh, aliquam sit amet eros a, vehicula eleifend tortor. Sed interdum tellus eu convallis pretium. Proin euismod felis id tortor semper, vel vehicula quam dapibus.']}]}, {'type': 'level_2', 'content': [{'type': 'title_2', 'content': ['Part 1-2']}, {'type': 'plain_text', 'content': ['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus.', 'Nulla odio nibh, aliquam sit amet eros a, vehicula eleifend tortor.']}]}]} \n",
      "\n",
      "{'type': 'level_1', 'content': [{'type': 'title_1', 'content': ['Part 2']}, {'type': 'level_2', 'content': [{'type': 'title_2', 'content': ['Part 2-1']}, {'type': 'plain_text', 'content': ['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus.']}]}, {'type': 'level_2', 'content': [{'type': 'title_2', 'content': ['Part 2-2']}, {'type': 'plain_text', 'content': ['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus. Nulla odio nibh, aliquam sit amet eros a, vehicula eleifend tortor.']}, {'type': 'level_3', 'content': [{'type': 'title_3', 'content': ['Part 2-2-1']}, {'type': 'plain_text', 'content': ['Lorem ipsum dolor sit amet, consectetur adipiscing elit.', 'Deuxieme texte']}]}]}]} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_slides = data['document_content']\n",
    "for elem in json_slides:\n",
    "    print(elem, \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_elements = []\n",
    "breakdown_json(json_slides, slide_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def retrieve_content(list_slides):\n",
    "    \"\"\"\n",
    "    Retrieves titles and plain texts from slide elements (can get them with breakdown_json)\n",
    "    Parameters:\n",
    "        - list_slides : list of data in json format\n",
    "    \"\"\"\n",
    "    keywords = ['level_', 'title_', 'subtitle', 'header']\n",
    "    doc_content = []\n",
    "    sublist = []\n",
    "    for content in list_slides:\n",
    "        r = [content for keyword in keywords if keyword in content]\n",
    "        if len(r)==0:\n",
    "            if filling == True:\n",
    "                sublist.append(content)\n",
    "            if content == 'plain_text':\n",
    "                doc_content.append(sublist)\n",
    "                sublist = []\n",
    "                filling = True\n",
    "        elif len(r)>0:\n",
    "            filling = False\n",
    "\n",
    "    return doc_content[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus. Fusce vitae lobortis quam. Proin laoreet efficitur ligula, laoreet congue neque condimentum a']\n",
      "1 ['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed.']\n",
      "2 ['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus.', 'Nulla odio nibh, aliquam sit amet eros a, vehicula eleifend tortor. Sed interdum tellus eu convallis pretium. Proin euismod felis id tortor semper, vel vehicula quam dapibus.']\n",
      "2 ['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus.', 'Nulla odio nibh, aliquam sit amet eros a, vehicula eleifend tortor.']\n",
      "1 ['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus.']\n",
      "1 ['Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus. Nulla odio nibh, aliquam sit amet eros a, vehicula eleifend tortor.']\n"
     ]
    }
   ],
   "source": [
    "for item in retrieve_content(slide_elements):\n",
    "    print(len(item), item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def retrieve_content_and_titles(list_slides, l):\n",
    "    \"\"\"\n",
    "    Retrieves titles and plain texts from json file\n",
    "    Parameters:\n",
    "        - list_slides : list of data in json format\n",
    "        - l : the list to be returned\n",
    "    \"\"\"\n",
    "    if (type(list_slides) == type(list())):\n",
    "        for value in list_slides:\n",
    "            if type(value) == type(str()):\n",
    "                l.append(value)\n",
    "            else:\n",
    "                retrieve_content_and_titles(value, l)\n",
    "    elif (type(list_slides) == type(dict())):\n",
    "        for key,value in list_slides.items():\n",
    "            retrieve_content_and_titles(value, l)\n",
    "    else:\n",
    "        pass\n",
    "        #print(type(list_slides))\n",
    "\n",
    "testl= []\n",
    "retrieve_content_and_titles(json_slides, testl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document title \n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus. Fusce vitae lobortis quam. Proin laoreet efficitur ligula, laoreet congue neque condimentum a \n",
      "\n",
      "Part 1 \n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed. \n",
      "\n",
      "Part 1-1 \n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus. \n",
      "\n",
      "Nulla odio nibh, aliquam sit amet eros a, vehicula eleifend tortor. Sed interdum tellus eu convallis pretium. Proin euismod felis id tortor semper, vel vehicula quam dapibus. \n",
      "\n",
      "Part 1-2 \n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus. \n",
      "\n",
      "Nulla odio nibh, aliquam sit amet eros a, vehicula eleifend tortor. \n",
      "\n",
      "Part 2 \n",
      "\n",
      "Part 2-1 \n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus. \n",
      "\n",
      "Part 2-2 \n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce diam ipsum, aliquam sit amet tempor sed, sodales vitae tellus. Nulla odio nibh, aliquam sit amet eros a, vehicula eleifend tortor. \n",
      "\n",
      "Part 2-2-1 \n",
      "\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. \n",
      "\n",
      "Deuxieme texte \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in testl:\n",
    "    print(i,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction based summurazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"Peter and Elizabeth took a taxi to attend the night party in the city. While in the party, Elizabeth collapsed and was rushed to the hospital. Since she was diagnosed with a brain injury, the doctor told Peter to stay besides her until she gets well. Therefore, Peter stayed with her at the hospital for 3 days without leaving.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "# https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_dictionary_table(text_string) -> dict:\n",
    "   \n",
    "    #removing stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    words = word_tokenize(text_string)\n",
    "    \n",
    "    #reducing words to their root form\n",
    "    stem = PorterStemmer()\n",
    "    \n",
    "    #creating dictionary for the word frequency table\n",
    "    frequency_table = dict()\n",
    "    for wd in words:\n",
    "        wd = stem.stem(wd)\n",
    "        if wd in stop_words:\n",
    "            continue\n",
    "        if wd in frequency_table:\n",
    "            frequency_table[wd] += 1\n",
    "        else:\n",
    "            frequency_table[wd] = 1\n",
    "\n",
    "    return frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_sentence_scores(sentences, frequency_table) -> dict:   \n",
    "\n",
    "    #algorithm for scoring a sentence by its words\n",
    "    sentence_weight = dict()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_wordcount = (len(word_tokenize(sentence)))\n",
    "        sentence_wordcount_without_stop_words = 0\n",
    "        for word_weight in frequency_table:\n",
    "            if word_weight in sentence.lower():\n",
    "                sentence_wordcount_without_stop_words += 1\n",
    "                if sentence[:7] in sentence_weight:\n",
    "                    sentence_weight[sentence[:7]] += frequency_table[word_weight]\n",
    "                else:\n",
    "                    sentence_weight[sentence[:7]] = frequency_table[word_weight]\n",
    "\n",
    "        sentence_weight[sentence[:7]] = sentence_weight[sentence[:7]] / sentence_wordcount_without_stop_words      \n",
    "\n",
    "    return sentence_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_average_score(sentence_weight) -> int:\n",
    "   \n",
    "    #calculating the average score for the sentences\n",
    "    sum_values = 0\n",
    "    for entry in sentence_weight:\n",
    "        sum_values += sentence_weight[entry]\n",
    "\n",
    "    #getting sentence average value from source text\n",
    "    average_score = (sum_values / len(sentence_weight))\n",
    "\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_article_summary(sentences, sentence_weight, threshold):\n",
    "    sentence_counter = 0\n",
    "    article_summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:7] in sentence_weight and sentence_weight[sentence[:7]] >= (threshold):\n",
    "            article_summary += \" \" + sentence\n",
    "            sentence_counter += 1\n",
    "            \n",
    "    return article_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_article_summary(article):\n",
    "    \n",
    "    #creating a dictionary for the word frequency table\n",
    "    frequency_table = _create_dictionary_table(article)\n",
    "\n",
    "    #tokenizing the sentences\n",
    "    sentences = sent_tokenize(article)\n",
    "\n",
    "    #algorithm for scoring a sentence by its words\n",
    "    sentence_scores = _calculate_sentence_scores(sentences, frequency_table)\n",
    "\n",
    "    #getting the threshold\n",
    "    threshold = _calculate_average_score(sentence_scores)\n",
    "\n",
    "    #producing the summary\n",
    "    article_summary = _get_article_summary(sentences, sentence_scores, threshold)\n",
    "\n",
    "    return article_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " While in the party, Elizabeth collapsed and was rushed to the hospital. Therefore, Peter stayed with her at the hospital for 3 days without leaving.\n"
     ]
    }
   ],
   "source": [
    "summary_results = _run_article_summary(article)\n",
    "print(summary_results)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "frequency_table = _create_dictionary_table(article)\n",
    "frequency_table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sentences = sent_tokenize(article)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sentence_scores = _calculate_sentence_scores(sentences, frequency_table)\n",
    "sentence_scores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "threshold = _calculate_average_score(sentence_scores)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "article_summary = _get_article_summary(sentences, sentence_scores, threshold)\n",
    "article_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
